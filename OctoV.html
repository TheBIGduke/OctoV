<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OctoV with WebSocket</title>
    <style>
        /* Basic page styling for fullscreen, centered canvas and overlay text */
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            color: #fff;
            font-family: 'Inter', sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }
        canvas {
            display: block;
        }
        #status {
            position: absolute;
            top: 20px;
            width: 100%;
            text-align: center;
            font-size: 1.2em;
            color: #aaa;
            text-shadow: 0 0 5px #000;
            transition: opacity 1s ease-in-out;
        }
    </style>
</head>
<body>

    <p id="status">Requesting audio permissions...</p>

    <script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.157.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.157.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        // Import Three.js and required addons
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { UnrealBloomPass } from 'three/addons/postprocessing/UnrealBloomPass.js';
        import { OutputPass } from 'three/addons/postprocessing/OutputPass.js';

        // --- DOM Elements ---
        const statusEl = document.getElementById('status');

        // --- Global Variables ---
        let scene, camera, renderer, composer, controls, sphere, clock, analyser, dataArray;
        let audioStream, audioContext; // Keep track of audio stream and context

        // --- State and Target Variables for smooth transitions and mode switching ---
        let currentMode = 'TTS'; // Current visual mode: 'USER' or 'TTS'
        let targetColor = new THREE.Color(0x00ddff).multiplyScalar(1.2); // Target color for smooth color transitions
        let targetScaleValue = 0.6;      // Target scale for sphere
        let targetSensitivity = 0.20;    // Target sensitivity for audio reactivity
        let targetRotationSpeed = 0.5;   // Target auto-rotation speed for OrbitControls

        // --- Initialization function: sets up scene, camera, renderer, controls, geometry, shaders, and post-processing ---
        function init() {
            // Listen for custom 'sourceChange' events to switch visual modes
            window.addEventListener('sourceChange', (event) => {
                const source = event.detail.source;
                currentMode = source;
                console.log(`API source changed to: ${source}`);

                // Set target values for smooth transitions depending on mode
                if (source === 'USER') {
                    targetColor.set(0xebcf34).multiplyScalar(1);
                    targetScaleValue = 0.3;
                    targetSensitivity = 0.15;
                    targetRotationSpeed = 7.0;
                    setupAudio('USB Audio Device'); // Switch to Microphone
                } else if (source === 'TTS') {
                    targetColor.set(0x00ddff).multiplyScalar(1.2);
                    targetScaleValue = 0.6;
                    targetSensitivity = 0.20;
                    targetRotationSpeed = 0.5;
                    setupAudio('Monitor of USB Audio Device Analog Stereo'); // Switch to system audio
                }
            });

            // Create Three.js scene and clock for animation timing
            scene = new THREE.Scene();
            clock = new THREE.Clock();

            // Set up perspective camera
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 2.5;

            // Set up WebGL renderer with tone mapping for better color
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.toneMapping = THREE.ACESFilmicToneMapping;
            renderer.toneMappingExposure = 1.0;
            document.body.appendChild(renderer.domElement);

            // Add orbit controls for interactive camera movement
            controls = new OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.autoRotate = true;
            controls.autoRotateSpeed = 0.5;

            // Create a high-detail icosahedron sphere geometry
            const sphereGeometry = new THREE.IcosahedronGeometry(1, 10);

            // Custom shader material for organic, audio-reactive wireframe sphere
            const sphereMaterial = new THREE.ShaderMaterial({
                uniforms: {
                    u_time: { value: 0.0 }, // Animation time
                    u_frequency: { value: 0.0 }, // Audio frequency average
                    u_color: { value: new THREE.Color(0x00ddff).multiplyScalar(1.2) }, // Sphere color
                    u_sensitivity: { value: 0.20} // Audio reactivity
                },
                vertexShader: `
                    uniform float u_time;
                    uniform float u_frequency;
                    uniform float u_sensitivity;

                    // 3D Perlin Noise function (credit: Stefan Gustavson)
                    vec3 mod289(vec3 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
                    vec4 mod289(vec4 x) { return x - floor(x * (1.0 / 289.0)) * 289.0; }
                    vec4 permute(vec4 x) { return mod289(((x*34.0)+1.0)*x); }
                    vec4 taylorInvSqrt(vec4 r) { return 1.79284291400159 - 0.85373472095314 * r; }
                    float snoise(vec3 v) {
                        const vec2 C = vec2(1.0/6.0, 1.0/3.0);
                        const vec4 D = vec4(0.0, 0.5, 1.0, 2.0);
                        vec3 i = floor(v + dot(v, C.yyy));
                        vec3 x0 = v - i + dot(i, C.xxx);
                        vec3 g = step(x0.yzx, x0.xyz);
                        vec3 l = 1.0 - g;
                        vec3 i1 = min(g.xyz, l.zxy);
                        vec3 i2 = max(g.xyz, l.zxy);
                        vec3 x1 = x0 - i1 + C.xxx;
                        vec3 x2 = x0 - i2 + C.yyy;
                        vec3 x3 = x0 - D.yyy;
                        i = mod289(i);
                        vec4 p = permute(permute(permute(
                            i.z + vec4(0.0, i1.z, i2.z, 1.0))
                            + i.y + vec4(0.0, i1.y, i2.y, 1.0))
                            + i.x + vec4(0.0, i1.x, i2.x, 1.0));
                        float n_ = 0.142857142857;
                        vec3 ns = n_ * D.wyz - D.xzx;
                        vec4 j = p - 49.0 * floor(p * ns.z * ns.z);
                        vec4 x_ = floor(j * ns.z);
                        vec4 y_ = floor(j - 7.0 * x_);
                        vec4 x = x_ * ns.x + ns.yyyy;
                        vec4 y = y_ * ns.x + ns.yyyy;
                        vec4 h = 1.0 - abs(x) - abs(y);
                        vec4 b0 = vec4(x.xy, y.xy);
                        vec4 b1 = vec4(x.zw, y.zw);
                        vec4 s0 = floor(b0)*2.0 + 1.0;
                        vec4 s1 = floor(b1)*2.0 + 1.0;
                        vec4 sh = -step(h, vec4(0.0));
                        vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy;
                        vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww;
                        vec3 p0 = vec3(a0.xy,h.x);
                        vec3 p1 = vec3(a0.zw,h.y);
                        vec3 p2 = vec3(a1.xy,h.z);
                        vec3 p3 = vec3(a1.zw,h.w);
                        vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2,p2), dot(p3,p3)));
                        p0 *= norm.x; p1 *= norm.y; p2 *= norm.z; p3 *= norm.w;
                        vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);
                        m = m * m;
                        return 42.0 * dot(m*m, vec4(dot(p0,x0), dot(p1,x1), dot(p2,x2), dot(p3,x3)));
                    }

                    void main() {
                        float freq = u_frequency / 90.0;
                        float noise = snoise(position * (1.0 + freq * 0.8) + u_time * 0.1);
                        float displacement = noise * freq * u_sensitivity;
                        vec3 newPosition = position + normal * displacement;
                        gl_Position = projectionMatrix * modelViewMatrix * vec4(newPosition, 1.0);
                    }
                `,
                fragmentShader: `
                    uniform vec3 u_color;
                    void main() {
                        gl_FragColor = vec4(u_color, 1.0);
                    }
                `,
                wireframe: true // Show only wireframe for a glowing effect
            });
            sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
            scene.add(sphere);

            // --- Post-Processing Pipeline ---
            composer = new EffectComposer(renderer);
            const renderPass = new RenderPass(scene, camera);
            composer.addPass(renderPass);

            // Add UnrealBloomPass for glowing effect
            const bloomPass = new UnrealBloomPass(new THREE.Vector2(window.innerWidth, window.innerHeight), 1.5, 0.4, 0.85);
            bloomPass.threshold = 0.4;
            bloomPass.strength = 0.7;
            bloomPass.radius = 0.5;
            composer.addPass(bloomPass);

            // Output pass for final rendering
            const outputPass = new OutputPass();
            composer.addPass(outputPass);

            // Handle window resizing
            window.addEventListener('resize', onWindowResize, false);
        }

        // --- Adjust camera and renderer on window resize ---
        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            composer.setSize(window.innerWidth, window.innerHeight);
        }

        // --- Animation loop: updates controls, sphere, and renders the scene ---
        function animate() {
            requestAnimationFrame(animate);
            controls.update();

            // Update shader time uniform for animation
            if (sphere && sphere.material.uniforms.u_time) {
                 sphere.material.uniforms.u_time.value = clock.getElapsedTime();
            }

            // If audio analyser is ready, update frequency data and drive visual changes
            if (analyser) {
                analyser.getByteFrequencyData(dataArray);
                let sum = dataArray.reduce((a, b) => a + b, 0);
                const average = sum / dataArray.length || 0;

                // Smoothly update frequency uniform for organic motion
                sphere.material.uniforms.u_frequency.value += (average - sphere.material.uniforms.u_frequency.value) * 0.10;

                // In USER mode, pulsate sphere scale based on audio level
                if (currentMode === 'USER') {
                    const audioLevel = dataArray[0] / 255;
                    const pulseAmount = audioLevel * 0.25;
                    targetScaleValue = 0.6 + pulseAmount;
                }

                // Smoothly interpolate all target values for transitions
                const lerpFactor = 0.05;
                sphere.scale.lerp(new THREE.Vector3(targetScaleValue, targetScaleValue, targetScaleValue), lerpFactor);
                sphere.material.uniforms.u_color.value.lerp(targetColor, lerpFactor);
                controls.autoRotateSpeed += (targetRotationSpeed - controls.autoRotateSpeed) * lerpFactor;
                sphere.material.uniforms.u_sensitivity.value += (targetSensitivity - sphere.material.uniforms.u_sensitivity.value) * lerpFactor;
            }

            // Render the scene with post-processing
            composer.render();
        }

        // --- Set up Web Audio API analyser for the selected audio device ---
        async function setupAudio(deviceLabel) {
            try {
                // Stop any existing audio stream to switch devices
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                if (audioContext) {
                    audioContext.close();
                }

                statusEl.textContent = `Searching for audio device: "${deviceLabel}"...`;
                statusEl.style.opacity = '1';

                // Request permission and enumerate devices
                await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                const devices = await navigator.mediaDevices.enumerateDevices();
                const audioInputs = devices.filter(device => device.kind === 'audioinput');

                const targetDevice = audioInputs.find(device => device.label.includes(deviceLabel));

                if (!targetDevice) {
                    console.warn(`Could not find device with label containing "${deviceLabel}". Available devices:`, audioInputs);
                    statusEl.innerHTML = `Error: Could not find audio device: "${deviceLabel}". <br/> Check the console (F12) for a list of available devices.`;
                    return;
                }

                statusEl.textContent = 'Device found. Starting visualization...';

                // Get stream from the target device
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: { deviceId: { exact: targetDevice.deviceId } }
                });

                // Create new audio context and analyser
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(audioStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 64;
                analyser.smoothingTimeConstant = 0.8;
                source.connect(analyser);

                dataArray = new Uint8Array(analyser.frequencyBinCount);

                statusEl.textContent = 'Visualization running...';
                setTimeout(() => { statusEl.style.opacity = '0'; }, 2000);

            } catch (err) {
                console.error("Error setting up audio source:", err);
                if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                    statusEl.textContent = 'Error: You must grant microphone permission.';
                } else {
                    statusEl.textContent = `Error: Could not start audio. ${err.message}`;
                }
            }
        }

        // --- WebSocket Connection ---
        function setupWebSocket() {
            const socket = new WebSocket('ws://localhost:9030');

            socket.onopen = () => {
                console.log('WebSocket connection established.');
                statusEl.textContent = 'Connected to WebSocket server.';
                setTimeout(() => { statusEl.style.opacity = '0'; }, 2000);
            };

            socket.onmessage = (event) => {
                try {
                    const message = JSON.parse(event.data);
                    if (message.source && (message.source === 'USER' || message.source === 'TTS')) {
                        console.log(`Received command to switch to ${message.source} mode.`);
                        window.dispatchEvent(new CustomEvent('sourceChange', { detail: { source: message.source } }));
                    }
                } catch (error) {
                    console.error('Error parsing WebSocket message:', error);
                }
            };

            socket.onclose = () => {
                console.log('WebSocket connection closed. Attempting to reconnect in 3 seconds...');
                statusEl.textContent = 'WebSocket connection lost. Reconnecting...';
                statusEl.style.opacity = '1';
                setTimeout(setupWebSocket, 3000); // Try to reconnect every 3 seconds
            };

            socket.onerror = (error) => {
                console.error('WebSocket error:', error);
                statusEl.textContent = 'WebSocket connection error.';
                statusEl.style.opacity = '1';
            };
        }

        // --- Start everything ---
        init();
        animate();
        // Initial audio setup for the default TTS mode
        setupAudio('Monitor of Built-in Audio Analog Stereo');
        // Start WebSocket connection
        setupWebSocket();

    </script>
</body>
</html>